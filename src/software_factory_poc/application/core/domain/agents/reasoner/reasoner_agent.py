from dataclasses import dataclass
from typing import List
import re
import logging

from software_factory_poc.application.core.domain.agents.base_agent import BaseAgent
from software_factory_poc.application.core.ports.gateways.llm_gateway import LlmGateway
from software_factory_poc.application.core.domain.agents.scaffolding.scaffolding_order import ScaffoldingOrder
from software_factory_poc.application.core.ports.gateways.dtos import FileContent
from software_factory_poc.application.core.domain.exceptions.domain_error import DomainError
from software_factory_poc.infrastructure.observability.logger_factory_service import LoggerFactoryService

# Local Entities
from software_factory_poc.application.core.domain.agents.reasoner.llm_request import LlmRequest
from software_factory_poc.application.core.domain.agents.reasoner.token_metric import TokenMetric

logger = LoggerFactoryService.build_logger(__name__)

@dataclass
class ReasonerAgent(BaseAgent):
    """
    Agent responsible for reasoning about the requirements and generating the scaffolding code.
    Cohesive implementation that handles Prompt Construction and Output Parsing internally.
    """
    llm_gateway: LlmGateway
    model_name: str = "gpt-4-turbo"

    def generate_scaffolding(self, request: ScaffoldingOrder, context: str) -> List[FileContent]:
        # 1. Build Prompt (Internal Logic)
        prompt = self._construct_prompt(request, context)
        
        # 2. Call LLM
        # Note: Depending on Gateway implementation, it might accept raw prompt string or LlmRequest object.
        # The interface previously used `generate_code(prompt=..., model=...)`.
        # We keep using the gateway interface as defined.
        llm_response = self.llm_gateway.generate_code(prompt=prompt, model=self.model_name)
        
        # 3. Parse Response (Internal Logic)
        files = self._parse_artifacts(llm_response)
        
        # 4. Validate
        if not files:
            raise DomainError("El Agente de Razonamiento generó una respuesta vacía o con formato inválido. No se encontraron bloques <<<FILE:path>>>.")
            
        return files

    def _construct_prompt(self, request: ScaffoldingOrder, knowledge_context: str) -> str:
        """
        Constructs the deterministic 'Super Prompt' for the LLM.
        """
        # Validation / Diagnostics
        if not knowledge_context or not knowledge_context.strip():
            logger.warning(f"Generating prompt for {request.issue_key} WITHOUT Knowledge Context (Empty RAG).")
            knowledge_context = "No specific architecture documentation provided. Use standard best practices."

        # 1. System Persona & Role
        system_section = (
            f"ROLE: You are an Expert Software Architect specializing in {request.technology_stack}.\n"
            f"MISSION: Create a production-ready 'Skeleton Scaffolding' for a project named '{request.issue_key}'.\n"
        )

        # 2. Context (RAG)
        context_section = (
            f"--- ARCHITECTURAL STANDARDS (RAG CONTEXT) ---\n"
            f"{knowledge_context}\n"
            f"----------------------------------------------\n"
        )

        # 3. Task & Restrictions
        task_section = (
            f"--- TASK INSTRUCTIONS ---\n"
            f"Project Name: {request.issue_key}\n"
            f"Tech Stack: {request.technology_stack}\n"
            f"User Summary: {request.summary}\n"
            f"Detailed Instructions: {request.raw_instruction}\n\n"
            
            f"--- CRITICAL OUTPUT RULES ---\n"
            f"1. **Configuration Files**: Generate FULL content for gitignore, package.json/requirements.txt, Dockerfile, etc.\n"
            f"2. **Structure Only**: Do NOT generate business logic. Create folders and place a 'README.md' inside each architectural layer explaining its purpose.\n"
            f"3. **Format**: You MUST use the following format for every file. Do not use Markdown code blocks for the format itself.\n"
            f"   <<<FILE:path/to/file.ext>>>\n"
            f"   ...file content...\n"
            f"   <<<END>>>\n"
        )

        # 4. One-Shot Example (to enforce format)
        example_section = (
            f"--- EXAMPLE OUTPUT ---\n"
            f"<<<FILE:README.md>>>\n"
            f"# Project {request.issue_key}\n"
            f"Generated by Software Factory.\n"
            f"<<<END>>>\n"
            f"<<<FILE:src/main.py>>>\n"
            f"print('Hello World')\n"
            f"<<<END>>>\n"
        )

        # Combine
        full_prompt = f"{system_section}\n{context_section}\n{task_section}\n{example_section}"

        # Debug Logging
        logger.info(f"--- [DEBUG] FULL GENERATED PROMPT ({request.issue_key}) ---\n{full_prompt}\n--- [END PROMPT] ---")

        return full_prompt

    def _parse_artifacts(self, response_text: str) -> List[FileContent]:
        """
        Parses LLM response using deterministic regex to extract file paths and content.
        Pattern: <<<FILE:path>>>...content...<<<END>>>
        """
        files = []
        # ^\s* matches start of line with optional whitespace
        # <<<FILE:\s* matches marker with optional whitespace
        # [\w./-]+ matches path
        # \s*>>> matches trailing whitespace and closing bracket
        # content group captures everything until the END marker (handling empty body case)
        pattern = r"^\s*<<<FILE:\s*(?P<path>[\w./-]+)\s*>>>\s*\n(?P<content>.*?)\s*<<<END>>>"

        matches = re.finditer(pattern, response_text, re.MULTILINE | re.DOTALL)
        
        parsed_files: List[FileContent] = []
        for match in matches:
             path = match.group("path").strip()
             content = match.group("content") or ""
             
             if ".." in path or path.startswith("/"):
                 logger.warning(f"Skipping invalid path: {path}")
                 continue
             
             if not content.strip():
                 content = "# Empty file generated by Scaffolding Agent"
                 
             parsed_files.append(FileContent(path=path, content=content))
        
        return parsed_files
